---
layout: post
title: "Data Science Concepts: ETL"
date: 2015-04-16T21:06:53+02:00
categories: data-science
---

When working with data on a regular basis, there are a few concepts that you get to hear a lot. One of them is ETL, or [Extract Transform and Load][etl]

The [ETL][etl] processes are often used when data needs to be standarised. In short is the _art_ of getting data from several different sources, cleaning it transforming it, and getting it all together into a data storage.

Nowadays, this data storage might be, from a [SQLite](http://www.sqlite.org/), to a [data lake](http://en.wiktionary.org/wiki/data_lake).

But this process is extremely important, since the _quality_ and _cleanness_ of the data will impact severely on how the system is able to respond later when performing analysis.

Though **abstract** and **complex** as this might sound, a process like this one might be simply getting data from a few tables, getting a few selected columns an merging it into another table. But it also can be complex.

<blockquote><p>Clean your data or you won't be able to use it properly. Clean data speaks for itself.</p><footer><cite>Albert Camps</cite></footer></blockquote>

What data science concepts do you want me to explain? Do you want to hear more about _data science_ concepts?

[etl]: http://es.wikipedia.org/wiki/Extract,_transform_and_load
